{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 16:07:38,801- WARNINGâ€¢\tTamaki solver is unavailable: No path /home/mliu6/.conda/envs/qtensor_ai/lib/python3.9/site-packages/qtensor_ai-0.1.0-py3.9.egg/qtensor_ai/qtensor/thirdparty/tamaki_treewidth. Either install tamaki in /home/mliu6/.conda/envs/qtensor_ai/lib/python3.9/site-packages/qtensor_ai-0.1.0-py3.9.egg/qtensor_ai/qtensor/thirdparty/tamaki_treewidth or add `tw-heuristic` to your $PATH\n"
     ]
    }
   ],
   "source": [
    "from qtensor_ai.OpFactory import ParallelParametricGate, ParallelTorchFactory\n",
    "from qtensor_ai import ParallelComposer\n",
    "from qtensor_ai.Simulate import ParallelSimulator\n",
    "from qtensor_ai.Backend import ParallelTorchBackend\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from functools import partial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandU(ParallelParametricGate):\n",
    "    name = 'Rand'\n",
    "    _changes_qubits=(0, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _gen_tensor(**parameters):\n",
    "        return parameters['alpha']\n",
    "\n",
    "    def gen_tensor(self, **parameters):\n",
    "        if len(parameters) == 0:\n",
    "            tensor = self._gen_tensor(**self._parameters)\n",
    "        if self.is_inverse:\n",
    "            tensor = torch.permute(tensor, [0,2,1,4,3]).conj()\n",
    "        return tensor\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"{}\".format(self.name) +\n",
    "                \"({})\".format(','.join(map(str, self._qubits)))\n",
    "        )\n",
    "\n",
    "ParallelTorchFactory.RandU = RandU\n",
    "\n",
    "\n",
    "'''Compose the circuit to evaluate the trace of the target circuit'''\n",
    "class TraceEvaluationComposer(ParallelComposer):\n",
    "    \n",
    "    def __init__(self, n_qubits, com):\n",
    "        self.n_target_qubits = n_qubits\n",
    "        self.n_qubits = n_qubits*2\n",
    "        self.com = com\n",
    "        super().__init__(n_qubits*2)\n",
    "\n",
    "    def added_circuit(self):\n",
    "        for target_qubit in range(self.n_target_qubits):\n",
    "            control_qubit = target_qubit + self.n_target_qubits\n",
    "            self.apply_gate(self.operators.H, control_qubit)\n",
    "            self.apply_gate(self.operators.cX, control_qubit, target_qubit)\n",
    "\n",
    "    '''Building circuit whose first amplitude is the expectation value of the measured circuit wrt to the cost_operator'''\n",
    "    def updated_full_circuit(self, **parameters):\n",
    "\n",
    "\n",
    "\n",
    "        '''This line of code where we used to have self.com.n_batch = self.n_batch is inconsistent with the HybridModule implementation'''\n",
    "        \n",
    "\n",
    "\n",
    "        circuit = self.com.updated_full_circuit(**parameters)\n",
    "\n",
    "\n",
    "        self.n_batch = self.com.n_batch\n",
    "\n",
    "\n",
    "        self.builder.reset()\n",
    "        self.added_circuit()\n",
    "        first_part = self.builder.circuit\n",
    "        self.builder.inverse()\n",
    "        second_part = self.builder.circuit\n",
    "        self.builder.reset()\n",
    "        result_circuit = first_part + circuit + second_part\n",
    "        return result_circuit\n",
    "\n",
    "    def name(self):\n",
    "        return 'TraceEvaluation'\n",
    "\n",
    "\n",
    "class LocalRandomUnitaryComposer(ParallelComposer):\n",
    "\n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        super().__init__(n_qubits)\n",
    "\n",
    "    def _get_builder(self):\n",
    "        return self._get_builder_class()(self.n_qubits)\n",
    "\n",
    "    def updated_full_circuit(self, **parameters):\n",
    "        unitaries = parameters['unitaries']\n",
    "        self.n_batch = unitaries.shape[0]\n",
    "        self.builder.reset()\n",
    "        for qubit in range(self.n_qubits):\n",
    "            self.apply_gate(self.operators.M, qubit)\n",
    "        for layer in range(self.n_layers):\n",
    "            qubit = np.random.randint(self.n_qubits-1)\n",
    "            #print(unitaries[:, layer].shape)\n",
    "            self.apply_gate(self.operators.RandU, qubit, qubit+1, alpha=unitaries[:, layer])\n",
    "        return self.builder.circuit\n",
    "    \n",
    "    def name():\n",
    "        return 'Local_Random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_unitary_generator(n_batch, n_layers, n_qubits):\n",
    "    module = nn.Linear(1,1)\n",
    "    module.unitary = nn.Parameter(torch.rand(n_batch, n_layers, 2**n_qubits, 2**n_qubits, dtype=torch.cfloat))\n",
    "    orthmod = nn.utils.parametrizations.orthogonal(module, name='unitary')\n",
    "    results = orthmod.unitary.reshape(n_batch, n_layers, 2,2,2,2).detach()\n",
    "    return results\n",
    "\n",
    "def get_val(com, trace, sim, unitary):\n",
    "    peo = None\n",
    "    trace_circuit = trace.updated_full_circuit(unitaries=unitary)\n",
    "    result = sim.simulate_batch(trace_circuit, peo=peo)\n",
    "    return result.detach()\n",
    "\n",
    "def get_vals(n_qubits, n_layers, num):\n",
    "\n",
    "    com = LocalRandomUnitaryComposer(n_qubits, 2*n_layers)\n",
    "    trace = TraceEvaluationComposer(n_qubits, com)\n",
    "    sim = ParallelSimulator(backend=ParallelTorchBackend())\n",
    "    get_val_map_fn = partial(get_val, com, trace, sim)\n",
    "    pool = mp.Pool(num)\n",
    "    #unitaries = [random_unitary_generator(1, 2*n_layers, 2)[0] for i in range(num)]\n",
    "    unitaries = random_unitary_generator(num, 2*n_layers, 2).unsqueeze(1)\n",
    "    result = pool.map(get_val_map_fn, unitaries)\n",
    "    return torch.abs(torch.tensor(result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0004+0.0008j])\n",
      "Time taken for a single evaluation:  0.05547332763671875\n",
      "tensor([6.2445e-04, 2.7660e-03, 2.3442e-03, 1.8287e-03, 3.5030e-03, 9.5215e-04,\n",
      "        6.4737e-04, 4.4468e-03, 1.2972e-03, 1.1672e-03, 1.3113e-03, 2.5305e-03,\n",
      "        7.0406e-05, 3.4946e-04, 2.1406e-03, 1.0710e-03, 2.8717e-03, 1.6313e-03,\n",
      "        3.2831e-04, 4.6847e-04, 2.0729e-03, 2.6349e-03, 4.4700e-04, 7.4173e-04,\n",
      "        2.1781e-03, 2.5780e-03, 1.4669e-03, 1.7918e-03, 1.1295e-04, 9.3396e-04])\n",
      "Time taken for multiprocess evaluation:  0.6076977252960205\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 10\n",
    "n_layers = n_qubits * 2\n",
    "num = 30\n",
    "\n",
    "com = LocalRandomUnitaryComposer(n_qubits, 2*n_layers)\n",
    "trace = TraceEvaluationComposer(n_qubits, com)\n",
    "sim = ParallelSimulator(backend=ParallelTorchBackend())\n",
    "\n",
    "start = time.time()\n",
    "print(get_val(com,trace,sim,random_unitary_generator(num, 2*n_layers, 2)[0].unsqueeze(0)))\n",
    "stop = time.time()\n",
    "print('Time taken for a single evaluation: ', stop - start)\n",
    "start = time.time()\n",
    "print(get_vals(n_qubits, n_layers, num))\n",
    "stop = time.time()\n",
    "print('Time taken for multiprocess evaluation: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e37f52b1ac3a33a4d187d5ade9b87bf0015f2320ccb2f09d6ad5cc3e492454b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('qtensor-torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
